from HK_Data_Tool import hk_code_data, hk_tool
import os
from langchain.agents import initialize_agent, AgentType
from langchain_community.chat_models import ChatOpenAI  # æ›´æ–°ä¸ºæ–°çš„å¯¼å…¥æ–¹å¼
from dotenv import load_dotenv
from Data_Analyse_Tool import Analyse_Tools
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
import re

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
api_key = os.getenv("DEEPSEEK_API_KEY")

# åˆå§‹åŒ–LLM - ä½¿ç”¨æ–°çš„å¯¼å…¥æ–¹å¼é¿å…è­¦å‘Š
llm = ChatOpenAI(
    api_key=api_key,
    base_url="https://api.deepseek.com",
    model="deepseek-chat",
    temperature=0.7
)

# ===== 1. åˆ›å»ºæ•°æ®è·å–Agent =====
# ä½¿ç”¨æ–°çš„ä»£ç†åˆ›å»ºæ–¹å¼é¿å…è­¦å‘Š
get_hk_data_Agent = initialize_agent(
    llm=llm,
    tools=[hk_tool],
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True  # æ·»åŠ é”™è¯¯å¤„ç†
)

# ===== 2. åˆ›å»ºæ•°æ®åˆ†æAgent =====
system_prompt = """ï¼ˆä¿æŒåŸæ ·ï¼‰"""
Analyse_stock_Agent = initialize_agent(
    prompt=ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder("chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder("agent_scratchpad")
    ]),
    llm=llm,
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    tools=Analyse_Tools,
    verbose=True,
    handle_parsing_errors=True  # æ·»åŠ é”™è¯¯å¤„ç†
)


# ===== 3. åˆ›å»ºè‚¡ç¥¨åç§°æå–å‡½æ•° =====
def extract_stock_names(input_dict: dict) -> list:
    """ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–è‚¡ç¥¨åç§°"""
    query = input_dict.get("query", "")
    if not query:
        return []

    # ç®€å•åŒ¹é…ä¸­æ–‡/è‹±æ–‡/æ•°å­—ç»„åˆ
    pattern = r'[\u4e00-\u9fa5a-zA-Z0-9]+'
    potential_names = re.findall(pattern, query)

    # è¿‡æ»¤æ‰å¸¸è§éè‚¡ç¥¨è¯æ±‡ï¼ˆå¯æ ¹æ®éœ€è¦æ‰©å±•ï¼‰
    common_words = ["è‚¡ç¥¨", "åˆ†æ", "èµ°åŠ¿", "å¯¹æ¯”", "æ•°æ®", "è·å–", "æŸ¥è¯¢", "ä¸€ä¸‹", "å¸®æˆ‘", "å¹¶", "çš„", "å’Œ"]
    return [name for name in potential_names if name not in common_words]


# ===== 4. åˆ›å»ºé“¾å¼å·¥ä½œæµ =====
# æ­¥éª¤1: æå–è‚¡ç¥¨åç§°
stock_extractor = RunnableLambda(extract_stock_names)

# æ­¥éª¤2: æ•°æ®è·å–å·¥ä½œæµ
data_fetch_chain = (
        RunnablePassthrough.assign(stock_names=stock_extractor)
        | RunnableLambda(lambda x: {
    "input": f"è·å–{', '.join(x['stock_names'])}çš„æœ€æ–°æ•°æ®" if x['stock_names'] else "æ²¡æœ‰éœ€è¦è·å–çš„è‚¡ç¥¨",
    "stock_names": x["stock_names"]
})
        | RunnableLambda(lambda x: get_hk_data_Agent.run(x["input"]) if x['stock_names'] else "æ²¡æœ‰æ‰§è¡Œæ•°æ®è·å–")
        | RunnablePassthrough.assign(stock_names=lambda x: x["stock_names"])
)

# æ­¥éª¤3: æ•°æ®åˆ†æå·¥ä½œæµ
analysis_chain = (
        RunnablePassthrough.assign(original_query=lambda x: x["query"])
        | RunnableLambda(lambda x: Analyse_stock_Agent.run(x["original_query"]))
)

# å®Œæ•´å·¥ä½œæµ
full_workflow = (
        RunnablePassthrough.assign(
            fetched_data=lambda x: data_fetch_chain.invoke({"query": x["query"]})
        )
        | analysis_chain
        | StrOutputParser()
)

# ===== 5. ä½¿ç”¨ç¤ºä¾‹ =====
if __name__ == "__main__":
    # ç¤ºä¾‹æŸ¥è¯¢ - ç¡®ä¿æ˜¯å­—å…¸æ ¼å¼
    query = {"query": "å¸®æˆ‘æŸ¥ä¸€ä¸‹è…¾è®¯çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¹¶åˆ†æè¿‘æœŸèµ°åŠ¿å’Œé£é™©"}

    # æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
    try:
        print("\n" + "=" * 50)
        print("ğŸš€ å¼€å§‹å¤„ç†æŸ¥è¯¢...")
        print("=" * 50)

        result = full_workflow.invoke(query)

        print("\n" + "=" * 50)
        print("ğŸ’¡ æœ€ç»ˆåˆ†æç»“æœ:")
        print("=" * 50)
        print(result)
    except Exception as e:
        print("\n" + "=" * 50)
        print("âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™:")
        print("=" * 50)
        print(str(e))
        print("\nè¯·æ£€æŸ¥æ—¥å¿—è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯")