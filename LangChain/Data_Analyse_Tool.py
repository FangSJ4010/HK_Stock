from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_models import ChatOpenAI
import matplotlib.pyplot as plt
import textwrap
import re
import os
from longbridge.openapi import Config
from langchain.tools import Tool
from langchain_community.vectorstores import FAISS
import numpy as np
from datetime import datetime
from RAG_Data.Embedding_model import Creat_Embeddings
from dotenv import load_dotenv

load_dotenv()

# åˆå§‹åŒ–Longbridgeé…ç½®
config = Config(
    app_key=os.getenv("LONGPORT_APP_KEY"),
    app_secret=os.getenv("LONGPORT_APP_SECRET"),
    access_token=os.getenv("LONGPORT_ACCESS_TOKEN")
)

# é…ç½®è·¯å¾„
MODEL_PATH = "E:/Pycharm/LangChain/embedding"
FAISS_INDEX_PATH = "E:/Pycharm/LangChain/FAISS_Stock_Data"
INDEX_NAME = "hk_stock_index"


# åˆ›å»ºè‡ªå®šä¹‰åµŒå…¥å¯¹è±¡
embedding = Creat_Embeddings()

# è‚¡ç¥¨åç§°åˆ°ä»£ç æ˜ å°„
name_to_code = {
    "è…¾è®¯": "00700.HK",
    "é˜¿é‡Œå·´å·´": "09988.HK",
    "ç¾å›¢": "03690.HK",
    "å°ç±³": "01810.HK",
    "ç²¤æ¸¯æ¹¾": "01396.HK",
    "äº¬ä¸œ": "09618.HK",
    "ç™¾åº¦": "09888.HK",
    "ç½‘æ˜“": "09999.HK",
    "æ¯”äºšè¿ª": "01211.HK",
    "ä¸­å›½å¹³å®‰": "02318.HK",
}


# åŠ è½½ FAISS å‘é‡åº“
def load_faiss_index():
    """åŠ è½½ FAISS å‘é‡åº“"""
    if not os.path.exists(os.path.join(FAISS_INDEX_PATH, f"{INDEX_NAME}.faiss")):
        print(f"æœªå­˜å‚¨{INDEX_NAME}ç›¸å…³æ•°æ®")
        return None

    try:
        db = FAISS.load_local(FAISS_INDEX_PATH, embedding, index_name=INDEX_NAME, allow_dangerous_deserialization=True)
        print(f"å·²åŠ è½½è‚¡ç¥¨æ•°æ®ç´¢å¼•ï¼ŒåŒ…å« {db.index.ntotal} ä¸ªæ–‡æ¡£")
        return db

    except Exception as e:
        print(f"åŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
        return None

# åˆå§‹åŒ–å‘é‡åº“
vector_db = load_faiss_index()



# 1. åŸºç¡€æœç´¢å·¥å…·
def stock_search_tool(query: str, k: int = 5) -> str:
    """åœ¨å‘é‡åº“ä¸­æœç´¢ç›¸å…³è‚¡ç¥¨æ•°æ®"""
    if not vector_db:
        return "è‚¡ç¥¨æ•°æ®ç´¢å¼•æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ•°æ®"

    results = vector_db.similarity_search(query, k=k)

    output = []
    for i, doc in enumerate(results):
        stock_name = doc.metadata.get("stock_name", "æœªçŸ¥è‚¡ç¥¨")
        stock_code = doc.metadata.get("stock_code", "æœªçŸ¥ä»£ç ")
        update_time = doc.metadata.get("update_time", "æœªçŸ¥æ—¶é—´")

        # æ ¼å¼åŒ–æ–‡æœ¬æ‘˜è¦
        content = textwrap.fill(doc.page_content, width=80)

        output.append(
            f"ğŸ” {i + 1}. {stock_name} ({stock_code})\n"
            f"ğŸ•’ æ›´æ–°æ—¶é—´: {update_time}\n"
            f"ğŸ“ æ‘˜è¦: {content}\n"
            f"{'-' * 40}"
        )

    return "\n".join(output)


# 2. è¶‹åŠ¿åˆ†æå·¥å…·
def trend_analysis_tool(stock_names: str, days: int = 5) -> str:
    """
    åˆ†æè‚¡ç¥¨è¶‹åŠ¿ï¼Œè¿”å›æ–‡æœ¬æŠ¥å‘Šå’Œå›¾è¡¨è·¯å¾„
    è¾“å…¥: è‚¡ç¥¨åç§°ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰ï¼Œåˆ†æå¤©æ•°
    è¾“å‡º: è¶‹åŠ¿åˆ†ææŠ¥å‘Šå’Œå›¾è¡¨æ–‡ä»¶è·¯å¾„
    """
    # 1. è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei']  # Windows
    plt.rcParams['axes.unicode_minus'] = False

    stock_list = [name.strip() for name in stock_names.split(",")]

    if not vector_db:
        return "è‚¡ç¥¨æ•°æ®ç´¢å¼•æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ•°æ®"

    # æ”¶é›†æ‰€æœ‰ç›¸å…³æ–‡æ¡£
    all_docs = []
    for stock in stock_list:
        if stock not in name_to_code:
            continue

        # æœç´¢è¯¥è‚¡ç¥¨çš„æ‰€æœ‰æ–‡æ¡£
        query = f"{stock} {name_to_code[stock]}"
        docs = vector_db.similarity_search(query, k=10)
        all_docs.extend(docs)

    if not all_docs:
        return "æœªæ‰¾åˆ°ç›¸å…³è‚¡ç¥¨æ•°æ®"

    # è§£æKçº¿æ•°æ®
    kline_data = {}
    for doc in all_docs:
        stock_code = doc.metadata.get("stock_code")
        if not stock_code:
            continue

        # ä»æ–‡æ¡£å†…å®¹ä¸­æå–Kçº¿æ•°æ®
        content = doc.page_content
        kline_matches = re.findall(r"æœ€è¿‘Kçº¿:([^:]+):å¼€(\d+\.?\d*)/æ”¶(\d+\.?\d*)ï¼Œ", content)

        if not kline_matches:
            continue

        # ç»„ç»‡Kçº¿æ•°æ®
        if stock_code not in kline_data:
            kline_data[stock_code] = {
                "dates": [],
                "opens": [],
                "closes": [],
                "stock_name": doc.metadata.get("stock_name", stock_code)
            }

        for match in kline_matches:
            date_str, open_price, close_price = match
            kline_data[stock_code]["dates"].append(date_str)
            kline_data[stock_code]["opens"].append(float(open_price))
            kline_data[stock_code]["closes"].append(float(close_price))

    if not kline_data:
        return "æœªæ‰¾åˆ°Kçº¿æ•°æ®"

    # åˆ›å»ºè¶‹åŠ¿å›¾è¡¨
    plt.figure(figsize=(12, 8))

    for stock_code, data in kline_data.items():
        # åªå–æœ€è¿‘dayså¤©çš„æ•°æ®
        dates = data["dates"][-days:]
        closes = data["closes"][-days:]

        if len(dates) < 2:
            continue

        # è®¡ç®—ç§»åŠ¨å¹³å‡
        moving_avg = np.convolve(closes, np.ones(3) / 3, mode='valid')

        plt.plot(dates, closes, 'o-', label=f"{data['stock_name']} ({stock_code})")
        plt.plot(dates[1:-1], moving_avg, '--', alpha=0.5)

    plt.title(f"è‚¡ç¥¨ä»·æ ¼è¶‹åŠ¿ ({days}å¤©)")
    plt.xlabel("æ—¥æœŸ")
    plt.ylabel("æ”¶ç›˜ä»·")
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=45)
    plt.tight_layout()

    # ä¿å­˜å›¾è¡¨
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    chart_path = f"stock_trend_{timestamp}.png"
    plt.savefig(chart_path)
    plt.close()

    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    report = f"ğŸ“ˆ è‚¡ç¥¨è¶‹åŠ¿åˆ†ææŠ¥å‘Š ({days}å¤©)\n\n"
    report += f"åˆ†æè‚¡ç¥¨: {', '.join(stock_list)}\n"
    report += f"è¶‹åŠ¿å›¾è¡¨å·²ä¿å­˜è‡³: {chart_path}\n\n"

    # æ·»åŠ ç®€è¦åˆ†æ
    report += "åˆ†ææ‘˜è¦:\n"
    for stock_code, data in kline_data.items():
        if len(data["closes"]) < 2:
            continue

        latest_close = data["closes"][-1]
        prev_close = data["closes"][-2] if len(data["closes"]) > 1 else latest_close
        change = latest_close - prev_close
        change_percent = (change / prev_close) * 100 if prev_close != 0 else 0

        trend = "ä¸Šæ¶¨ğŸ“ˆ" if change > 0 else "ä¸‹è·ŒğŸ“‰" if change < 0 else "æŒå¹³â–"

        report += (
            f"- {data['stock_name']} ({stock_code}): "
            f"æœ€æ–°ä»· {latest_close:.2f} ({trend} {change_percent:.2f}%)\n"
        )

    return report + f"\nå›¾è¡¨è·¯å¾„: {chart_path}"


# 5. é£é™©åˆ†æå·¥å…·
def risk_analysis_tool(stock_name: str) -> str:
    """
    åˆ†æå•æ”¯è‚¡ç¥¨çš„é£é™©æŒ‡æ ‡
    è¾“å…¥: è‚¡ç¥¨åç§°
    è¾“å‡º: é£é™©åˆ†ææŠ¥å‘Š
    """
    if stock_name not in name_to_code:
        return f"æœªè¯†åˆ«çš„è‚¡ç¥¨åç§°: {stock_name}"

    if not vector_db:
        return "è‚¡ç¥¨æ•°æ®ç´¢å¼•æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ•°æ®"

    # æœç´¢è¯¥è‚¡ç¥¨çš„æœ€æ–°æ–‡æ¡£
    query = f"{stock_name} {name_to_code[stock_name]}"
    docs = vector_db.similarity_search(query, k=5)
    if not docs:
        return f"æœªæ‰¾åˆ° {stock_name} çš„ç›¸å…³æ•°æ®"

    # åˆ†ææ‰€æœ‰ç›¸å…³æ–‡æ¡£
    price_changes = []
    volumes = []
    for doc in docs:
        content = doc.page_content

        # æå–ä»·æ ¼å˜åŒ–
        change_matches = re.findall(r"æ¶¨è·Œå¹…:(-?\d+\.?\d*)%", content)
        if change_matches:
            price_changes.extend([float(change) for change in change_matches])

        # æå–æˆäº¤é‡
        volume_matches = re.findall(r"æˆäº¤é‡:([\d,]+)", content)
        if volume_matches:
            volumes.extend([int(vol.replace(",", "")) for vol in volume_matches])

    # è®¡ç®—é£é™©æŒ‡æ ‡
    report = f"âš ï¸ {stock_name} é£é™©åˆ†ææŠ¥å‘Š\n\n"

    if price_changes:
        volatility = np.std(price_changes)
        max_drop = min(price_changes)
        avg_change = np.mean(price_changes)

        report += "ğŸ“ˆ ä»·æ ¼æ³¢åŠ¨åˆ†æ:\n"
        report += f"- å¹³å‡æ—¥æ¶¨è·Œå¹…: {avg_change:.2f}%\n"
        report += f"- ä»·æ ¼æ³¢åŠ¨ç‡: {volatility:.2f}%\n"
        report += f"- æœ€å¤§å•æ—¥è·Œå¹…: {max_drop:.2f}%\n"

        if volatility > 5:
            report += "  â†’ é«˜é£é™©: ä»·æ ¼æ³¢åŠ¨å‰§çƒˆ\n"
        elif volatility > 2:
            report += "  â†’ ä¸­é£é™©: ä»·æ ¼æ³¢åŠ¨é€‚ä¸­\n"
        else:
            report += "  â†’ ä½é£é™©: ä»·æ ¼æ³¢åŠ¨å¹³ç¨³\n"
    else:
        report += "æœªæ‰¾åˆ°ä»·æ ¼æ³¢åŠ¨æ•°æ®\n"

    if volumes:
        volume_volatility = np.std(volumes) / np.mean(volumes) * 100
        min_volume = min(volumes)
        avg_volume = np.mean(volumes)

        report += "\nğŸ“Š æˆäº¤é‡åˆ†æ:\n"
        report += f"- å¹³å‡æˆäº¤é‡: {avg_volume:,.0f}\n"
        report += f"- æˆäº¤é‡æ³¢åŠ¨ç‡: {volume_volatility:.2f}%\n"
        report += f"- æœ€ä½æˆäº¤é‡: {min_volume:,.0f}\n"

        if volume_volatility > 50:
            report += "  â†’ é«˜é£é™©: æˆäº¤é‡æ³¢åŠ¨å‰§çƒˆ\n"
        elif volume_volatility > 30:
            report += "  â†’ ä¸­é£é™©: æˆäº¤é‡æ³¢åŠ¨æ˜æ˜¾\n"
        else:
            report += "  â†’ ä½é£é™©: æˆäº¤é‡æ³¢åŠ¨å¹³ç¨³\n"
    else:
        report += "æœªæ‰¾åˆ°æˆäº¤é‡æ•°æ®\n"

    # æ·»åŠ æ€»ä½“é£é™©è¯„ä¼°
    report += "\nğŸ” æ€»ä½“é£é™©è¯„ä¼°:\n"

    risk_level = "ä½"
    if price_changes and volumes:
        if volatility > 5 or volume_volatility > 50:
            risk_level = "é«˜"
        elif volatility > 3 or volume_volatility > 30:
            risk_level = "ä¸­"

    report += f"- é£é™©ç­‰çº§: {risk_level}\n"
    report += "- å»ºè®®: "

    if risk_level == "é«˜":
        report += "æ­¤è‚¡ç¥¨é£é™©è¾ƒé«˜ï¼ŒæŠ•èµ„éœ€è°¨æ…ï¼Œå»ºè®®å°ä»“ä½æˆ–é¿å…æŠ•èµ„"
    elif risk_level == "ä¸­":
        report += "æ­¤è‚¡ç¥¨é£é™©é€‚ä¸­ï¼Œå¯è€ƒè™‘é€‚é‡æŠ•èµ„ï¼Œä½†éœ€å¯†åˆ‡å…³æ³¨å¸‚åœºå˜åŒ–"
    else:
        report += "æ­¤è‚¡ç¥¨é£é™©è¾ƒä½ï¼Œé€‚åˆç¨³å¥å‹æŠ•èµ„è€…"

    return report


# 7. æ•°æ®æ›´æ–°å·¥å…·
def update_stock_data_tool(stock_names: str) -> str:
    """
    æ›´æ–°æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®
    è¾“å…¥: è‚¡ç¥¨åç§°ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰
    è¾“å‡º: æ›´æ–°ç»“æœæŠ¥å‘Š
    """
    stock_list = [name.strip() for name in stock_names.split(",")]

    # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æ•°æ®æ›´æ–°é€»è¾‘
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ä¹‹å‰çš„ add_or_update_stock_data å‡½æ•°

    # æ¨¡æ‹Ÿæ›´æ–°è¿‡ç¨‹
    results = []
    for stock in stock_list:
        if stock in name_to_code:
            results.append(f"{stock} æ•°æ®å·²æ›´æ–°")
        else:
            results.append(f"{stock} æœªè¯†åˆ«")

    return "æ›´æ–°ç»“æœ:\n- " + "\n- ".join(results)


# åˆ›å»ºå·¥å…·åˆ—è¡¨
Analyse_Tools = [
    Tool(
        name="è‚¡ç¥¨æœç´¢",
        func=stock_search_tool,
        description="æœç´¢è‚¡ç¥¨æ•°æ®ï¼Œè¾“å…¥æŸ¥è¯¢å†…å®¹ï¼Œè¿”å›ç›¸å…³è‚¡ç¥¨ä¿¡æ¯"
    ),
    Tool(
        name="è¶‹åŠ¿åˆ†æ",
        func=trend_analysis_tool,
        description="åˆ†æè‚¡ç¥¨ä»·æ ¼è¶‹åŠ¿ï¼Œè¾“å…¥è‚¡ç¥¨åç§°ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰å’Œå¤©æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤5å¤©ï¼‰ï¼Œè¿”å›è¶‹åŠ¿æŠ¥å‘Šå’Œå›¾è¡¨"
    ),
    Tool(
        name="é£é™©åˆ†æ",
        func=risk_analysis_tool,
        description="åˆ†æå•æ”¯è‚¡ç¥¨çš„é£é™©æŒ‡æ ‡ï¼Œè¾“å…¥è‚¡ç¥¨åç§°ï¼Œè¿”å›é£é™©æŠ¥å‘Š"
    ),
    Tool(
        name="æ•°æ®æ›´æ–°",
        func=update_stock_data_tool,
        description="æ›´æ–°æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®ï¼Œè¾“å…¥è‚¡ç¥¨åç§°ï¼ˆå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼‰ï¼Œè¿”å›æ›´æ–°ç»“æœ"
    )
]


# åˆ›å»º Agent
def create_agent():
    """åˆ›å»ºå¹¶è¿”å›è‚¡ç¥¨åˆ†æ Agent"""
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿ä½¿ç”¨å„ç§å·¥å…·åˆ†ææ¸¯è‚¡å¸‚åœºæ•°æ®ã€‚
    ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥åˆ†æFAISSæ•°æ®åº“ä¸­å­˜å‚¨çš„è‚¡ç¥¨æ•°æ®ï¼š
    - è‚¡ç¥¨æœç´¢ï¼šæœç´¢ç›¸å…³è‚¡ç¥¨ä¿¡æ¯
    - è¶‹åŠ¿åˆ†æï¼šåˆ†æè‚¡ç¥¨ä»·æ ¼è¶‹åŠ¿
    - ç›¸å…³æ€§åˆ†æï¼šåˆ†æå¤šä¸ªè‚¡ç¥¨ä¹‹é—´çš„ä»·æ ¼ç›¸å…³æ€§
    - åŸºæœ¬é¢å¯¹æ¯”ï¼šå¯¹æ¯”å¤šä¸ªè‚¡ç¥¨çš„åŸºæœ¬é¢æ•°æ®
    - é£é™©åˆ†æï¼šåˆ†æå•æ”¯è‚¡ç¥¨çš„é£é™©æŒ‡æ ‡
    - è¡Œä¸šåˆ†æï¼šåˆ†æç‰¹å®šè¡Œä¸šçš„è‚¡ç¥¨è¡¨ç°
    - æ•°æ®æ›´æ–°ï¼šæ›´æ–°æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®

    è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·è¿›è¡Œåˆ†æã€‚å¦‚æœç”¨æˆ·çš„é—®é¢˜éœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œå¯ä»¥è¿ç»­ä½¿ç”¨å¤šä¸ªå·¥å…·ã€‚

    å½“ä½¿ç”¨å›¾è¡¨ç”Ÿæˆå·¥å…·æ—¶ï¼Œè¯·å°†å›¾è¡¨è·¯å¾„åŒ…å«åœ¨å›å¤ä¸­ï¼Œä»¥ä¾¿ç”¨æˆ·æŸ¥çœ‹ã€‚

    ä½ çš„åˆ†æåº”è¯¥ä¸“ä¸šã€å…¨é¢ï¼Œå¹¶æä¾›æœ‰ä»·å€¼çš„æŠ•èµ„è§è§£ã€‚
    """

    # åˆ›å»ºæç¤ºæ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder("chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder("agent_scratchpad")
    ])

    # é€‰æ‹©LLMæ¨¡å‹
    api_key = os.getenv("DEEPSEEK_API_KEY")
    # å°è£… OpenAI æˆ–å…¼å®¹ API æˆä¸ºä¸€ä¸ª LangChain å¯ç”¨çš„è¯­è¨€æ¨¡å‹æ¥å£ï¼ˆLLMï¼‰
    llm = ChatOpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com",
        model="deepseek-chat",
        temperature=0.7  # æ§åˆ¶è¯­è¨€æ¨¡å‹è¾“å‡ºå†…å®¹ éšæœºæ€§ çš„å‚æ•°ï¼Œå®˜æ–¹æ¨è0.7
    )

    # åˆ›å»ºAgent
    agent = create_openai_functions_agent(llm, Analyse_Tools, prompt)

    # åˆ›å»ºæ‰§è¡Œå™¨
    agent_executor = AgentExecutor(
        agent=agent,
        tools=Analyse_Tools,
        verbose=True,
        return_intermediate_steps=True
    )

    return agent_executor


# åˆ›å»ºAgentå®ä¾‹
stock_analyst_agent = create_agent()

api_key = os.getenv("DEEPSEEK_API_KEY")
# å°è£… OpenAI æˆ–å…¼å®¹ API æˆä¸ºä¸€ä¸ª LangChain å¯ç”¨çš„è¯­è¨€æ¨¡å‹æ¥å£ï¼ˆLLMï¼‰
llm = ChatOpenAI(
    api_key=api_key,
    base_url="https://api.deepseek.com",
    model="deepseek-chat",
    temperature=0.7  # æ§åˆ¶è¯­è¨€æ¨¡å‹è¾“å‡ºå†…å®¹ éšæœºæ€§ çš„å‚æ•°ï¼Œå®˜æ–¹æ¨è0.7
)


# response = get_hk_data_Agent.run("å¸®æˆ‘æŸ¥ä¸€ä¸‹è…¾è®¯çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¹¶åˆ†æä¸€ä¸‹å½¢åŠ¿")
# print(response)
